(the resources coverd are from Prof. C.L. Wang's lecture slides)

![alt text](https://github.com/Richardxxxxxxx/interview/blob/master/image/spark-strengths.jpeg)
![alt text](https://github.com/Richardxxxxxxx/interview/blob/master/image/spark-strengths2.jpeg)
![alt text](https://github.com/Richardxxxxxxx/interview/blob/master/image/spark-strengths3.jpeg)
![alt text](https://github.com/Richardxxxxxxx/interview/blob/master/image/spark-strengths4.jpeg)
![alt text](https://github.com/Richardxxxxxxx/interview/blob/master/image/spark-rdd.jpeg)
![alt text](https://github.com/Richardxxxxxxx/interview/blob/master/image/spark-rdd2.jpeg)
![alt text](https://github.com/Richardxxxxxxx/interview/blob/master/image/spark-rdd3.jpeg)
![alt text](https://github.com/Richardxxxxxxx/interview/blob/master/image/spark-rdd4.jpeg)
![alt text](https://github.com/Richardxxxxxxx/interview/blob/master/image/spark-rdd5.jpeg)
![alt text](https://github.com/Richardxxxxxxx/interview/blob/master/image/spark-rdd6.jpeg)
![alt text](https://github.com/Richardxxxxxxx/interview/blob/master/image/spark-rdd7.jpeg)
![alt text](https://github.com/Richardxxxxxxx/interview/blob/master/image/spark-rdd8.jpeg)
![alt text](https://github.com/Richardxxxxxxx/interview/blob/master/image/spark-rdd9.jpeg)
![alt text](https://github.com/Richardxxxxxxx/interview/blob/master/image/spark-rdd10.jpeg)
![alt text](https://github.com/Richardxxxxxxx/interview/blob/master/image/spark-rdd11.jpeg)
![alt text](https://github.com/Richardxxxxxxx/interview/blob/master/image/spark-exe.jpeg)
![alt text](https://github.com/Richardxxxxxxx/interview/blob/master/image/spark-driver.jpeg)
![alt text](https://github.com/Richardxxxxxxx/interview/blob/master/image/spark-driver2.jpeg)
![alt text](https://github.com/Richardxxxxxxx/interview/blob/master/image/spark-onyarn.jpeg)
![alt text](https://github.com/Richardxxxxxxx/interview/blob/master/image/spark-flow.jpeg)

step1: Create RDDs

step2: Create Execution Plan(transform a logical execution plan (i.e. RDD lineage of dependencies built using RDD transformations) to a physical execution plan)

step3: Split “stage” into “tasks”, Schedule tasks, Schedule and Execute “Stage by Stage”





![alt text](https://github.com/Richardxxxxxxx/interview/blob/master/image/spark-DAG.jpeg)
![alt text](https://github.com/Richardxxxxxxx/interview/blob/master/image/spark-DAG2.jpeg)
![alt text](https://github.com/Richardxxxxxxx/interview/blob/master/image/spark-DAG3.jpeg)
![alt text](https://github.com/Richardxxxxxxx/interview/blob/master/image/spark-DAG4.jpeg)
![alt text](https://github.com/Richardxxxxxxx/interview/blob/master/image/spark-lazy.jpeg)
![alt text](https://github.com/Richardxxxxxxx/interview/blob/master/image/spark-fault.jpeg)
![alt text](https://github.com/Richardxxxxxxx/interview/blob/master/image/spark-fault2.jpeg)
![alt text](https://github.com/Richardxxxxxxx/interview/blob/master/image/spark-fault3.jpeg)
![alt text](https://github.com/Richardxxxxxxx/interview/blob/master/image/spark-fault4.jpeg)
![alt text](https://github.com/Richardxxxxxxx/interview/blob/master/image/spark-checkpoint.jpeg)
